# Performance Analysis

**File**: `./app/api/queries.py`  
**Time**: 02:19:39  
**Type**: performance_analysis

## Improvement

```python
import logging
from typing import List, Dict
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from app.services.product_data_service import ProductDataService
from app.services.ai_service import AIService
import re
import asyncio

# Setup logging
logger = logging.getLogger(__name__)

router = APIRouter()
product_service = ProductDataService()
ai_service = AIService()

class QueryRequest(BaseModel):
    question: str

class QueryResponse(BaseModel):
    answer: str
    products: List[dict]
    question: str
    note: str

@router.post("/ask", response_model=QueryResponse)
async def ask_question(request: QueryRequest):
    """Ask a question about products and get recommendations"""
    try:
        # Get AI response and relevant products concurrently
        ai_response_task = ai_service.get_response(request.question)

        # Ekstrak kategori dan max_price dari pertanyaan (sederhana)
        category = None
        max_price = None
        
        # Deteksi kategori dengan lebih lengkap
        question_lower = request.question.lower()
        category_mapping = {
            'laptop': ['laptop', 'notebook', 'komputer'],
            'smartphone': ['smartphone', 'hp', 'handphone', 'phone', 'telepon', 'ponsel'],
            'tablet': ['tablet', 'ipad'],
            'headphone': ['headphone', 'earphone', 'headset', 'audio'],
            'kamera': ['kamera', 'camera', 'fotografi'],
            'audio': ['audio', 'speaker', 'sound'],
            'tv': ['tv', 'televisi'],
            'drone': ['drone', 'quadcopter'],
            'jam': ['jam', 'watch', 'smartwatch']
        }

        for cat, keywords in category_mapping.items():
            if any(keyword in question_lower for keyword in keywords):
                category = cat
                break  # Stop after the first matching category

        # Simple price extraction (can be improved with more sophisticated NLP)
        price_match = re.search(r"(\d+(?:\.\d+)?)", request.question)
        if price_match:
            try:
                max_price = float(price_match.group(1))
            except ValueError:
                logger.warning(f"Could not parse price from question: {request.question}")
        
        product_promise = product_service.get_relevant_products(category, max_price)
        
        ai_response, relevant_products = await asyncio.gather(ai_response_task, product_promise)

        # Determine fallback message
        note = "Here are some relevant products we found."
        if not relevant_products:
            note = "Sorry, we couldn't find any products matching your request.  Here are some popular options."
            relevant_products = await product_service.get_popular_products()

        # Return the response
        return QueryResponse(
            answer=ai_response,
            products=relevant_products,
            question=request.question,
            note=note
        )

    except Exception as e:
        logger.exception("Error processing question")
        raise HTTPException(status_code=500, detail=str(e))
```

**Justification:**

The primary performance bottleneck is likely the sequential execution of `ai_service.get_response()` and `product_service.get_relevant_products()`. These are independent operations, and waiting for one to complete before starting the other wastes time.

The optimization involves using `asyncio.gather()` to run `ai_service.get_response()` and `product_service.get_relevant_products()` concurrently.  Specifically:

1.  **Create Tasks:** Instead of awaiting `ai_service.get_response()` immediately, we create a task `ai_response_task`.
2.  **`asyncio.gather()`:**  `asyncio.gather(ai_response_task, product_service.get_relevant_products(category, max_price))`  awaits both tasks concurrently. The results are returned in the order the tasks were passed to `gather`.
3.  **Unpack results:** We unpack the awaited results into `ai_response` and `relevant_products`.

This allows both the AI response and the product data to be fetched in parallel, significantly reducing the overall response time. This is especially beneficial if `ai_service.get_response()` and/or `product_service.get_relevant_products()` involve network requests or other I/O-bound operations.

---
*Generated by Smart AI Bot*
