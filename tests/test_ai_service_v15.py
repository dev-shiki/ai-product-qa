import pytest
from app.services.ai_service import generate_response

def test_generate_response_basic():
    # Mock 'get_settings' to avoid actual configuration loading
    with patch('app.utils.config.get_settings') as mock_get_settings:
        mock_get_settings.return_value = MagicMock(GOOGLE_API_KEY="dummy_key")

        # Mock 'genai.Client' and its 'models.generate_content' method
        with patch('google.genai.Client') as mock_genai_client:
            # Configure the mock response from the AI model
            mock_ai_response = MagicMock()
            mock_ai_response.text = "This is a mocked AI response based on your context."
            mock_genai_client.return_value.models.generate_content.return_value = mock_ai_response

            # Import AIService only after its dependencies are patched to ensure mocks are active
            from app.services.ai_service import AIService
            
            # Instantiate the AIService
            ai_service = AIService()

            # Define a simple test context
            test_context = "I am looking for a high-performance laptop."

            # Expected parts of the prompt generated by the function
            expected_prompt_start = "You are a helpful product assistant. Based on the following context, provide a helpful and informative response:\n\n"
            expected_prompt_end = "\nPlease provide a clear and concise answer that helps the user understand the products and make an informed decision."
            
            # Call the function under test
            actual_response = ai_service.generate_response(test_context)

            # Assertions
            # 1. Verify that generate_content was called exactly once
            mock_genai_client.return_value.models.generate_content.assert_called_once()
            
            # 2. Get the arguments with which generate_content was called
            args, kwargs = mock_genai_client.return_value.models.generate_content.call_args
            
            # 3. Check the model name
            assert kwargs['model'] == "gemini-2.0-flash"
            
            # 4. Check the contents (prompt)
            assert isinstance(kwargs['contents'], str)
            assert kwargs['contents'].startswith(expected_prompt_start)
            assert test_context in kwargs['contents']
            assert kwargs['contents'].endswith(expected_prompt_end)

            # 5. Verify the returned value
            assert isinstance(actual_response, str)
            assert actual_response == "This is a mocked AI response based on your context."
